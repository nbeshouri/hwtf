{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Match(a=10, b=0, size=10)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "# def replace_mention(\n",
    "\n",
    "e = 'Professor Farnsworth'\n",
    "f = 'Farnsworth'\n",
    "matcher = difflib.SequenceMatcher(None, e, f)\n",
    "match = matcher.find_longest_match(0, len(e), 0, len(f))\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# Due to a bug, this language model doesn't contain\n",
    "# stop words, so we fix that here.\n",
    "for word in nlp.Defaults.stop_words:\n",
    "    lex = nlp.vocab[word]\n",
    "    lex.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "def show_parse(sentence, style='dep'):\n",
    "    parsed = nlp(sentence)\n",
    "    svg = displacy.render(parsed, style=style)\n",
    "    with open('sentence.svg', 'w') as f:\n",
    "        f.write(svg)\n",
    "\n",
    "    displacy.render(parsed, style=style, jupyter=True)\n",
    "    \n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_text = \"\"\"A self-described mad scientist, the Professor is a \n",
    "          senile, amoral, deranged, and unpredictable old man \n",
    "          (160 years old as of \"A Clone of My Own\"), with very \n",
    "          thick glasses and a gift for creating doomsday devices \n",
    "          and atomic supermen. He has put at least one parallel \n",
    "          universe in peril with his inventions and visited dozens \n",
    "          more (see The Farnsworth Parabox).\n",
    "\n",
    "          The Professor teaches at Mars University and has worked for \n",
    "          Momcorp on several occasions, but spends most of his time \n",
    "          inventing ridiculous devices and sending the Planet Express \n",
    "          delivery crew on suicide missions. While at Momcorp, he fell \n",
    "          in love with the CEO, Mom, only to leave her and Momcorp when \n",
    "          she decided to weaponize his \"Q.T. McWhiskers\" toy. What he is \n",
    "          a professor of is never explicitly stated. In the episode Mars \n",
    "          University when asked what he is teaching, he responds: \n",
    "          \"The same thing I teach every semester, the mathematics of \n",
    "          quantum neutrino fields. I made up the title so no student \n",
    "          would dare take it\"; however, this declaration has not precluded \n",
    "          the professor from demonstrating mastery of whatever field of science \n",
    "          is convenient for a given episode's plot, as shown in Bender's Big Score \n",
    "          when he proclaims, \"I can wire anything directly into anything! I am the \n",
    "          Professor!\", proceeding to link Hermes' disembodied head to the ship's \n",
    "          computer. Approximately 100 years before the series' timeline, he taught a\n",
    "          young (not yet Professor) Wernstrom, whom Farnsworth regarded as a prized \n",
    "          student. After he returned a pop quiz to Wernstrom with a grade of A-minus \n",
    "          (for poor penmanship), the two became bitter rivals (established in \"A Big \n",
    "          Piece of Garbage\").\"\"\"\n",
    "\n",
    "big_text = text.replace('\\n', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_title = 'Professor Farnsworth'\n",
    "article_title = article_title.lower()\n",
    "\n",
    "relevant_subjects = []\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        if token.dep_ == 'nsubj' and token.text.lower() in article_title:\n",
    "            relevant_subjects.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nsubj\n",
      "'m ROOT\n",
      "obi compound\n",
      "- punct\n",
      "wan compound\n",
      "- punct\n",
      "ki attr\n",
      ". punct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I 'm obi - wan - ki .\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_sent = nlp(sent)\n",
    "for token in parsed_sent:\n",
    "    print(token.text, token.dep_)\n",
    "' '.join(token.text for token in parsed_sent)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"The heinous Professor Farnsworth treacherously killed Obi-wan.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1450\" height=\"399.5\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">heinous</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Professor</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Farnsworth</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">treacherously</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">killed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Obi-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">wan.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "The heinous Professor Farnsworth treacherously killed Obi-wan."
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_parse(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The heinous Professor Farnsworth treacherously killed Obi-wan.'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokens_to_str(tokens, spaces_before_punct=False):\n",
    "    tokens = list(tokens)\n",
    "    strings = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        is_first_word = i == 0\n",
    "        \n",
    "        cur_not_string = not isinstance(token, str)\n",
    "        last_two_not_str = i >= 1 and cur_not_string and not isinstance(tokens[i - 1], str)\n",
    "        last_three_not_str = i >= 2 and last_two_not_str and not isinstance(tokens[i - 2], str)\n",
    "        is_dash_after_compound = last_two_not_str and token.text == '-' and tokens[i - 1].dep_ == 'compound'\n",
    "        is_token_after_dash = last_three_not_str and tokens[i - 1].text == '-' and tokens[i - 2].dep_ == 'compound'\n",
    "        cur_is_punct = cur_not_string and (token.is_punct or token.dep_ == 'case')\n",
    "        \n",
    "        skip_space = is_first_word or is_dash_after_compound or is_token_after_dash or (cur_is_punct and not spaces_before_punct)\n",
    "        \n",
    "        if not isinstance(token, str):\n",
    "            token = token.text\n",
    "        \n",
    "        token = token.strip()\n",
    "        if not token:\n",
    "            continue\n",
    "        \n",
    "        if not skip_space:\n",
    "            strings.append(' ')\n",
    "            \n",
    "        strings.append(token)\n",
    "        \n",
    "    return ''.join(strings)\n",
    "\n",
    "tokens_to_str(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The heinous <TARGET> killed <OBJECT>.']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parsed = nlp(sent)\n",
    "# noun = parsed[5]\n",
    "\n",
    "# print(list(noun.head.subtree))\n",
    "import re\n",
    "\n",
    "def filter_sent(sent_text, target_name, cap_first_word=True):\n",
    "    \n",
    "    remove_patterns = [r'\\(.+?\\)', r'\\[.+?\\]']\n",
    "    for pattern in remove_patterns:\n",
    "        sent_text = re.sub(pattern, '', sent_text)\n",
    "    \n",
    "    parsed_sent = nlp(sent_text)\n",
    "    \n",
    "    # Extract\n",
    "    subjects_of_interest = []\n",
    "    for token in parsed_sent:\n",
    "        if token.dep_ == 'nsubj' and token.text.lower() in target_name.lower():\n",
    "            subjects_of_interest.append(token)\n",
    "    \n",
    "    output = []\n",
    "    for subj in subjects_of_interest:\n",
    "        selected_tokens = []\n",
    "        subtree_heads = list(subj.head.children)\n",
    "        \n",
    "        for token in subj.head.subtree:\n",
    "            if token == subj.head or token.head == subj.head:\n",
    "                selected_tokens.append(token)\n",
    "        \n",
    "        if selected_tokens[0].dep_ == 'dobj':\n",
    "            dobj = selected_tokens.pop(0)\n",
    "            verb_index = selected_tokens.index(subj.head)\n",
    "            selected_tokens.insert(verb_index + 1, dobj)\n",
    "        \n",
    "        final_tokens = []   \n",
    "        for token in selected_tokens:\n",
    "            if token == subj:\n",
    "                subj_str = tokens_to_str(token.subtree)\n",
    "                matcher = difflib.SequenceMatcher(None, target_name, subj_str)\n",
    "                match = matcher.find_longest_match(0, len(target_name), 0, len(subj_str))\n",
    "                subj_str = subj_str[:match.b] + '<TARGET>' + subj_str[match.b + match.size:]\n",
    "                final_tokens.append(subj_str)\n",
    "            elif token.dep_ == 'attr':\n",
    "                final_tokens.extend(token.subtree)\n",
    "            elif token == subj.head:\n",
    "                final_tokens.append(token.text)\n",
    "            elif token.dep_ == 'dobj':\n",
    "                final_tokens.append('<OBJECT>')\n",
    "         \n",
    "        final_tokens.append(nlp('.')[0])\n",
    "        as_str = tokens_to_str(final_tokens)\n",
    "        if cap_first_word:\n",
    "            split = as_str.split(' ')\n",
    "            if '<' not in split[0]:\n",
    "                as_str = ' '.join([split[0].capitalize()] + split[1:])\n",
    "        output.append(as_str)\n",
    "            \n",
    "    return output\n",
    "    \n",
    "filter_sent(\"The heinous Professor Farnsworth treacherously killed the monster of New York while traveling east.\", 'Professor Farnsworth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The heinous <TARGET> killed <OBJECT>.']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parsed = nlp(sent)\n",
    "# noun = parsed[5]\n",
    "\n",
    "# print(list(noun.head.subtree))\n",
    "import re\n",
    "\n",
    "def filter_sent(sent_text, target_name, cap_first_word=True):\n",
    "    \n",
    "    remove_patterns = [r'\\(.+?\\)', r'\\[.+?\\]']\n",
    "    for pattern in remove_patterns:\n",
    "        sent_text = re.sub(pattern, '', sent_text)\n",
    "    \n",
    "    parsed_sent = nlp(sent_text)\n",
    "    \n",
    "    # Extract\n",
    "    subjects_of_interest = []\n",
    "    for token in parsed_sent:\n",
    "        if token.dep_ == 'nsubj' and token.text.lower() in target_name.lower():\n",
    "            subjects_of_interest.append(token)\n",
    "    \n",
    "    output = []\n",
    "    for subj in subjects_of_interest:\n",
    "        selected_tokens = []\n",
    "        subtree_heads = list(subj.head.children)\n",
    "        \n",
    "        for token in subj.head.subtree:\n",
    "            if token == subj.head or token.head == subj.head:\n",
    "                selected_tokens.append(token)\n",
    "        \n",
    "        if selected_tokens[0].dep_ == 'dobj':\n",
    "            dobj = selected_tokens.pop(0)\n",
    "            verb_index = selected_tokens.index(subj.head)\n",
    "            selected_tokens.insert(verb_index + 1, dobj)\n",
    "        \n",
    "        basic_filters = [(lambda x: x.pos_ == 'PROPN', '<PROPN>')]\n",
    "        \n",
    "        final_tokens = []   \n",
    "        for token in selected_tokens:\n",
    "            if token == subj:\n",
    "                subj_str = tokens_to_str(token.subtree)\n",
    "                matcher = difflib.SequenceMatcher(None, target_name, subj_str)\n",
    "                match = matcher.find_longest_match(0, len(target_name), 0, len(subj_str))\n",
    "                subj_str = subj_str[:match.b] + '<TARGET>' + subj_str[match.b + match.size:]\n",
    "                final_tokens.append(subj_str)\n",
    "            elif token.dep_ == 'attr':\n",
    "                filtered_sub = filter_subtree(token, basic_filters)\n",
    "                final_tokens.extend(filtered_sub)\n",
    "            elif token == subj.head:\n",
    "                final_tokens.append(token.text)\n",
    "            elif token.dep_ == 'dobj':\n",
    "                final_tokens.append('<OBJECT>')\n",
    "         \n",
    "        final_tokens.append(nlp('.')[0])\n",
    "        as_str = tokens_to_str(final_tokens)\n",
    "        if cap_first_word:\n",
    "            split = as_str.split(' ')\n",
    "            if '<' not in split[0]:\n",
    "                as_str = ' '.join([split[0].capitalize()] + split[1:])\n",
    "        output.append(as_str)\n",
    "            \n",
    "    return output\n",
    "    \n",
    "filter_sent(\"The heinous Professor Farnsworth treacherously killed the monster of New York while traveling east.\", 'Professor Farnsworth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-423-757528228783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfast_nlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/aind/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__call__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.parse_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.get_batch_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/aind/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/aind/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         X, bp_layer = layer.begin_update(layer.ops.flatten(seqs_in, pad=pad),\n\u001b[0;32m--> 280\u001b[0;31m                                          drop=drop)\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/aind/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/aind/lib/python3.6/site-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mresidual_bwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/aind/lib/python3.6/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/aind/lib/python3.6/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/aind/lib/python3.6/site-packages/thinc/neural/_classes/maxout.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mbest__bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich__bo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mbest__bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest__bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    fast_nlp('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_replace(head):\n",
    "    if head.pos_ == 'PROPN':\n",
    "        return ['<OBJECT>']\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Avatar, Aang, is, a, fictional, character, and, the, protagonist, of, Nickelodeon, 's, animated, television, series, Avatar, :]\n",
      "Avatar\n",
      "[Avatar, Aang, is, a, fictional, character, and, the, protagonist, of, Nickelodeon, 's, animated, television, series, Avatar, :]\n",
      "Avatar\n",
      "[Avatar, Aang, is, a, fictional, character, and, the, protagonist, of, Nickelodeon, 's, animated, television, series, Avatar, :]\n",
      "Aang\n",
      "[Avatar, Aang, is, a, fictional, character, and, the, protagonist, of, Nickelodeon, 's, animated, television, series, Avatar, :]\n",
      "Nickelodeon\n",
      "[Avatar, Aang, is, a, fictional, character, and, the, protagonist, of, Nickelodeon, 's, animated, television, series, Avatar, :]\n",
      "'s\n",
      "[Avatar, Aang, is, a, fictional, character, and, the, protagonist, of, Nickelodeon, 's, animated, television, series, Avatar, :]\n",
      "Avatar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Avatar,\n",
       " Aang,\n",
       " is,\n",
       " a,\n",
       " fictional,\n",
       " character,\n",
       " and,\n",
       " the,\n",
       " protagonist,\n",
       " of,\n",
       " Nickelodeon,\n",
       " 's,\n",
       " animated,\n",
       " television,\n",
       " series,\n",
       " Avatar,\n",
       " :]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_proper_nouns(subtree):\n",
    "    subtree = list(subtree)\n",
    "    output = subtree[:]\n",
    "    for token in subtree:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            for subtoken in token.subtree:\n",
    "                print(output)\n",
    "                print(subtoken)\n",
    "#                 if subtoken != token:\n",
    "#                 output.remove(subtoken)\n",
    "#             output[output.index(token)] = '<OBJECT>'\n",
    "    return output\n",
    "\n",
    "sent = \"\"\"Avatar Aang is a fictional character and the protagonist of Nickelodeon's animated television series Avatar: The Last Airbender.\"\"\"\n",
    "parsed = nlp(sent)\n",
    "replace_proper_nouns(parsed[1].head.subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The <TARGET> is a senile, amoral, deranged, and unpredictable old man.',\n",
       " 'The <TARGET> teaches.',\n",
       " '<TARGET> regarded <OBJECT>.']"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'Professor Farnsworth'\n",
    "sent= \"\"\"A self-described mad scientist, the Professor is a \n",
    "  senile, amoral, deranged, and unpredictable old man with very \n",
    "  thick glasses and a gift for creating doomsday devices \n",
    "  and atomic supermen.\"\"\"\n",
    "sent = sent.replace('\\n', '')\n",
    "filter_sent(big_text, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Aang\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is the last surviving \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Airbender\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", a monk of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Air Nomads'\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Southern Air Temple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       ". He was created by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Jim Dale\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avatar 0 \n",
      "Aang 0 PERSON\n",
      "( 0 \n",
      "安昂 0 \n",
      "Ān 0 \n",
      "Áng 0 \n",
      ") 0 \n",
      "is 0 \n",
      "a 0 \n",
      "fictional 0 \n",
      "character 0 \n",
      "and 0 \n",
      "the 0 \n",
      "protagonist 0 \n",
      "of 0 \n",
      "Nickelodeon 0 ORG\n",
      "'s 0 \n",
      "animated 0 \n",
      "television 0 \n",
      "series 0 \n",
      "Avatar 0 WORK_OF_ART\n",
      ": 0 WORK_OF_ART\n",
      "The 0 \n",
      "Last 0 \n",
      "Airbender 0 PRODUCT\n",
      "( 0 \n",
      "created 0 \n",
      "by 0 \n",
      "Michael 0 PERSON\n",
      "Dante 0 PERSON\n",
      "DiMartino 0 PERSON\n",
      "and 0 \n",
      "Bryan 0 PERSON\n",
      "Konietzko 0 PERSON\n",
      ") 0 \n",
      ", 0 \n",
      "voiced 0 \n",
      "by 0 \n",
      "Zach 0 PERSON\n",
      "Tyler 0 PERSON\n",
      "Eisen 0 PERSON\n",
      ". 0 \n",
      "\n",
      "\n",
      " 0 CARDINAL\n",
      "Aang 0 PERSON\n",
      "is 0 \n",
      "the 0 \n",
      "last 0 \n",
      "surviving 0 \n",
      "Airbender 0 PRODUCT\n",
      ", 0 \n",
      "a 0 \n",
      "monk 0 \n",
      "of 0 \n",
      "the 0 ORG\n",
      "Air 0 ORG\n",
      "Nomads 0 ORG\n",
      "' 0 ORG\n",
      "Southern 0 FAC\n",
      "Air 0 FAC\n",
      "Temple 0 FAC\n",
      ". 0 \n",
      "He 0 \n",
      "is 0 \n",
      "an 0 \n",
      "incarnation 0 \n",
      "of 0 \n",
      "the 0 \n",
      "\" 0 \n",
      "Avatar 0 PRODUCT\n",
      "\" 0 \n",
      ", 0 \n",
      "the 0 \n",
      "spirit 0 \n",
      "of 0 \n",
      "light 0 \n",
      "and 0 \n",
      "peace 0 \n",
      "manifested 0 \n",
      "in 0 \n",
      "human 0 \n",
      "form 0 \n",
      ". 0 \n",
      "As 0 \n",
      "the 0 \n",
      "Avatar 0 PRODUCT\n",
      ", 0 \n",
      "Aang 0 PERSON\n",
      "controls 0 \n",
      "all 0 \n",
      "four 0 CARDINAL\n",
      "elements 0 \n",
      "and 0 \n",
      "is 0 \n",
      "tasked 0 \n",
      "with 0 \n",
      "keeping 0 \n",
      "the 0 ORG\n",
      "Four 0 ORG\n",
      "Nations 0 ORG\n",
      "at 0 \n",
      "peace 0 \n",
      ". 0 \n",
      "At 0 \n",
      "12 0 DATE\n",
      "years 0 DATE\n",
      "old 0 DATE\n",
      ", 0 \n",
      "Aang 0 PERSON\n",
      "is 0 \n",
      "the 0 \n",
      "series 0 \n",
      "' 0 \n",
      "reluctant 0 \n",
      "hero 0 \n",
      ", 0 \n",
      "spending 0 \n",
      "a 0 \n",
      "century 0 \n",
      "in 0 \n",
      "suspended 0 \n",
      "animation 0 \n",
      "before 0 \n",
      "joining 0 \n",
      "new 0 \n",
      "friends 0 \n",
      "Katara 0 PERSON\n",
      "and 0 \n",
      "Sokka 0 PERSON\n",
      "on 0 \n",
      "a 0 \n",
      "quest 0 \n",
      "to 0 \n",
      "master 0 \n",
      "the 0 \n",
      "elements 0 \n",
      "and 0 \n",
      "save 0 \n",
      "their 0 \n",
      "world 0 \n",
      "from 0 \n",
      "the 0 \n",
      "imperialist 0 \n",
      "Fire 0 ORG\n",
      "Nation 0 ORG\n",
      ". 0 \n",
      "\n",
      "\n",
      " 0 CARDINAL\n",
      "Aang 0 PERSON\n",
      "'s 0 \n",
      "character 0 \n",
      "has 0 \n",
      "appeared 0 \n",
      "in 0 \n",
      "other 0 \n",
      "media 0 \n",
      ", 0 \n",
      "such 0 \n",
      "as 0 \n",
      "trading 0 \n",
      "cards,[1][2 0 \n",
      "] 0 \n",
      "video 0 \n",
      "games,[3][4 0 \n",
      "] 0 \n",
      "T 0 \n",
      "- 0 \n",
      "shirts,[5 0 \n",
      "] 0 \n",
      "and 0 \n",
      "web 0 \n",
      "comics.[6 0 \n",
      "] 0 \n",
      "Aang 0 PERSON\n",
      "has 0 \n",
      "also 0 \n",
      "been 0 \n",
      "portrayed 0 \n",
      "by 0 \n",
      "Noah 0 PERSON\n",
      "Ringer 0 PERSON\n",
      "in 0 \n",
      "the 0 \n",
      "feature 0 \n",
      "film 0 \n",
      "The 0 WORK_OF_ART\n",
      "Last 0 WORK_OF_ART\n",
      "Airbender,[7 0 WORK_OF_ART\n",
      "] 0 \n",
      "and 0 \n",
      "voiced 0 \n",
      "by 0 \n",
      "D.B. 0 PERSON\n",
      "Sweeney 0 PERSON\n",
      "in 0 \n",
      "the 0 \n",
      "sequel 0 \n",
      "animated 0 \n",
      "series 0 \n",
      "The 0 WORK_OF_ART\n",
      "Legend 0 WORK_OF_ART\n",
      "of 0 WORK_OF_ART\n",
      "Korra 0 WORK_OF_ART\n",
      ". 0 \n"
     ]
    }
   ],
   "source": [
    "sent = \"\"\"Aang is the last surviving Airbender, a monk of the Air Nomads' Southern Air Temple. He was created by Jim Dale.\"\"\"\n",
    "show_parse(sent, style='ent')\n",
    "parsed = nlp(anng)\n",
    "for token in parsed:\n",
    "    print(token, token.ent_id, token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "anng = \"\"\"Avatar Aang is a fictional character and the protagonist of Nickelodeon's animated television series Avatar: The Last Airbender (created by Michael Dante DiMartino and Bryan Konietzko), voiced by Zach Tyler Eisen.\n",
    "\n",
    "Aang is the last surviving Airbender, a monk of the Air Nomads' Southern Air Temple. He is an incarnation of the \"Avatar\", the spirit of light and peace manifested in human form. As the Avatar, Aang controls all four elements and is tasked with keeping the Four Nations at peace. At 12 years old, Aang is the series' reluctant hero, spending a century in suspended animation before joining new friends Katara and Sokka on a quest to master the elements and save their world from the imperialist Fire Nation.\n",
    "\n",
    "Aang's character has appeared in other media, such as trading cards,[1][2] video games,[3][4] T-shirts,[5] and web comics.[6] Aang has also been portrayed by Noah Ringer in the feature film The Last Airbender,[7] and voiced by D.B. Sweeney in the sequel animated series The Legend of Korra.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"As the Avatar, Aang controls all four elements and is tasked with keeping the Four Nations at peace.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<TARGET> is a fictional character and the protagonist of <PROPN> animated television series <PROPN>.',\n",
       " '<TARGET> is <PROPN>.',\n",
       " '<TARGET> controls <OBJECT>.',\n",
       " \"<TARGET> is the series' reluctant hero.\"]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_sent(anng, 'Avatar Aang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avatar compound\n",
      "Aang nsubj\n",
      "is ROOT\n",
      "a det\n",
      "fictional amod\n",
      "character attr\n",
      "and cc\n",
      "the det\n",
      "protagonist conj\n",
      "of prep\n",
      "Nickelodeon poss\n",
      "'s case\n",
      "animated amod\n",
      "television compound\n",
      "series pobj\n",
      "Avatar appos\n",
      ": punct\n",
      "The det\n",
      "Last amod\n",
      "Airbender ROOT\n",
      ". punct\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(sent):\n",
    "    print(token, token.dep_, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo():\n",
    "    pass\n",
    "hasattr(foo, '__call__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Avatar, Aang, is, a, fictional, character, and, the, protagonist, :]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_subtree(head, rules):\n",
    "    for rule, replacement in rules:\n",
    "        if rule(head):\n",
    "            if callable(replacement):\n",
    "                replacement = replacement(head)\n",
    "            return [replacement]\n",
    "    if len(list(head.children)) == 0:\n",
    "        return [head]\n",
    "    output = []\n",
    "    for child in head.lefts:\n",
    "        output.extend(get_subtree(child, rules))\n",
    "    output.append(head)\n",
    "    for child in head.rights:\n",
    "        output.extend(get_subtree(child, rules))\n",
    "    \n",
    "    return [token for token in output if token]\n",
    "\n",
    "rules = [\n",
    "    (lambda x: x.dep_ == 'prep', None),\n",
    "\n",
    "]\n",
    "\n",
    "get_subtree(head, rules)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Avatar,\n",
       " Aang,\n",
       " is,\n",
       " a,\n",
       " fictional,\n",
       " character,\n",
       " and,\n",
       " the,\n",
       " protagonist,\n",
       " of,\n",
       " '<OBJECT>',\n",
       " :]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_subtree(head, dead_ends, exceptions=None):\n",
    "    if head.dep_ in dead_ends:\n",
    "        return ['<OBJECT>']\n",
    "    elif len(list(head.children)) == 0:\n",
    "        return [head]\n",
    "    output = []\n",
    "    for child in head.lefts:\n",
    "        output.extend(get_subtree(child, dead_ends))\n",
    "    output.append(head)\n",
    "    for child in head.rights:\n",
    "        output.extend(get_subtree(child, dead_ends))\n",
    "    \n",
    "    return output\n",
    "    \n",
    "\n",
    "parsed = nlp(sent)\n",
    "\n",
    "head = parsed[2]\n",
    "get_subtree(head, ['pobj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack nsubj 95\n",
      "\n",
      "the det 89\n",
      "golden amod 83\n",
      "goose dobj 91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent= \"\"\"Jack killed the golden goose.\"\"\"\n",
    "sent = sent.replace('\\n', '')\n",
    "sent = nlp(sent)\n",
    "for word in sent:\n",
    "    if word.dep_ == 'nsubj' or word.dep_ == 'dobj':\n",
    "        for e in word.subtree:\n",
    "            print(e, e.dep_, e.pos)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
